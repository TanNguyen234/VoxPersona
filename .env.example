# ── Pipeline mode ──
# speech_to_speech : STT → LLM → TTS  (full voice loop, loads all models)
# llm_tts          : LLM → TTS        (text in, voice out — no Whisper)
# llm_only         : LLM              (text in, text out — lightest)
PIPELINE_MODE=speech_to_speech

# Hugging Face model IDs
WHISPER_MODEL_ID=openai/whisper-large-v3-turbo
QWEN_MODEL_ID=Qwen/Qwen2.5-7B-Instruct

# Runtime
DEVICE=auto
MAX_HISTORY=10
MAX_NEW_TOKENS=256
TEMPERATURE=0.7
TOP_P=0.9
REPETITION_PENALTY=1.2
ASR_CHUNK_LENGTH_S=30
MIC_SAMPLE_RATE=16000
MIC_CHANNELS=1
MIC_RECORD_SECONDS=6

# ── VAD (continuous mic) ──
VAD_ENERGY_THRESHOLD=0.02
VAD_SILENCE_DURATION_MS=800
VAD_MIN_SPEECH_MS=400
VAD_MAX_SPEECH_S=30.0

# ── F5-TTS (CLI-based, requires: python scripts/setup_models.py) ──
F5_ENABLED=false
F5_REF_AUDIO=./vocals.wav
F5_REF_TEXT=
F5_OUTPUT_PATH=./outputs/tts_response.wav
F5_SPEED=1.0
F5_MODEL=F5TTS_Base
F5_VOCODER=vocos

# Checkpoint files — leave empty for F5 default, or point to vendor:
F5_CKPT_FILE=
F5_VOCAB_FILE=

# Vietnamese example:
# F5_CKPT_FILE=./vendor/F5-TTS-Vietnamese/ckpts/model_last.pt
# F5_VOCAB_FILE=./vendor/F5-TTS-Vietnamese/ckpts/vocab.txt
